{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b294c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer as stemmer\n",
    "from tqdm.notebook import tqdm\n",
    "import rule_book_functs as rbfuncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_fn = \"data/source/20220413_D1_Incidents.csv\"\n",
    "rule_book_fn = \"data/rule_book_kwic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv(rule_book_fn)\n",
    "incidents = pd.read_csv(incidents_fn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ecaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.rename(columns={'IncidentNumber': 'incident_id'}, inplace=True)\n",
    "incidents['text'] = (\n",
    "        incidents['ShortDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['FullDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['ImmediateAction'].astype(str).fillna('')\n",
    ").str.lower()\n",
    "\n",
    "incidents = incidents[['incident_id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample100 = incidents.sample(n=100)\n",
    "#sample100.index = range(100)\n",
    "#sample100.to_csv('sample100.csv', index=False)\n",
    "sample100 = pd.read_csv('sample100.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#incidents.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = incidents.text.head(1).apply(rbfuncts.lemmatize_text)\n",
    "#print(list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ef026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = incidents.text.head(1).apply(rbfuncts.stem_text)\n",
    "#print(list(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_tokens = rbfuncts.tokenize(incidents.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chk_text = 'employee was grinding with a four-inch grinder on an iron support in the compressor building when he felt discomfort to his left eye.'\n",
    "#pattern = '(\\\\bemployee (.*) discomfort (.*) eye\\\\b)'\n",
    "#rbfuncts.check_presence(pattern, chk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents = sent_tokenize(incidents.text[0])\n",
    "#for sent in sents:\n",
    "#    if rbfuncts.check_presence(pattern, sent):\n",
    "#        print(f'{rbfuncts.check_presence(pattern, sent)}: {sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6b6e9",
   "metadata": {},
   "source": [
    "## Load Synonyms & Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ac4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_csv = pd.read_csv('synonyms.csv')\n",
    "\n",
    "# Load the dictionary of synonyms\n",
    "syn_dict = {}\n",
    "for r in range(len(syn_csv)):\n",
    "    syn_toks = syn_csv.keywords[r].split(',')\n",
    "    syn_dict.update({syn_csv.syn[r]:syn_toks})\n",
    "    \n",
    "rul_csv = pd.read_csv('rules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6a6267",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds_df = rbfuncts.rule_book_scan(sample100, syn_dict, rul_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae123a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c48301e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = 'This is me. He tripped and fell from the ladder.'\n",
    "#strs = 'during the scaffolding elements transporting for the assembly of scaffolding scaffolder slipped and fell due to the slippery floor'\n",
    "test = pd.DataFrame({'incident_id':[1052], 'text':[strs]})\n",
    "rbfuncts.rule_book_scan(test, syn_dict, rul_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(not False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many incidents were classified\n",
    "len(list(dict.fromkeys(finds_df[finds_df.finds_list == True].incid_nums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfuncts.deepdive_results(sample100, incidents, finds_df, focus='finds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130bb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfuncts.deepdive_results(sample100, incidents, finds_df, focus='misses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = 'the country gm and regional gm were on their way to their apartment when they were involved in a motor vehicle collision.'\n",
    "#check_presence('hello(.*)vehicle(.*)collision', chk)\n",
    "#check_presence('\\bregional (.*) were (.*) way\\b', chk)\n",
    "#bool(re.search('\\bregional (.*) were (.*) way\\b', chk))\n",
    "bool(re.search('involved(.*)motor(.*)collision', chk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c02807",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0db66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_string = \"This is employee's hand\"\n",
    "pattern = r\"'s\"\n",
    "\n",
    "# Replace all occurrences of character 's with an empty string\n",
    "org_string = re.sub(pattern, '', org_string )\n",
    "print(org_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_presence(pattern, string):\n",
    "    if pattern:\n",
    "        return bool(re.search(pattern, string))\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39db40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'car(.*)hit(.*)\\\\bcat'\n",
    "pattern = x\n",
    "check_presence(pattern, \"the car hit the cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(r\"\\\\\\\\b\", \"\\\\b\", 'no\\\\\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5941b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'id':[1, 2, 2, 2, 3], 'cats':['apple', 'apple', 'apple', 'orange', 'kiwi']})\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby(['id'])['cats'].apply(', '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af811b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'apple, apple, orange'.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dict.fromkeys('apple, apple, orange'.split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\", \".join(list(dict.fromkeys('apple, apple, orange'.split(', '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dups(ent):\n",
    "    split_ent = ent.split(', ')\n",
    "    uniqe_ent = list(dict.fromkeys(split_ent))\n",
    "    rjoin_ent = \", \".join(uniqe_ent)\n",
    "    return(rjoin_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b05cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dups('apple, apple, orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64629339",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.groupby(['id'])['cats'].apply(', '.join).reset_index()\n",
    "test['cats'] = test['cats'].apply(lambda x: remove_dups(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99340c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in [1, 2, 3]:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds_count = 0\n",
    "finds_count+=1\n",
    "finds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import sys\n",
    "\n",
    "for i in range(200):\n",
    "    sys.stdout.write('\\r')\n",
    "    # the exact output you're looking for:\n",
    "    sys.stdout.write(str(i))\n",
    "    sys.stdout.flush()\n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490af6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5286e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "then = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6705ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = then - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68eb18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(diff.seconds/(60*60), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(60*60/(60*60), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 10000\n",
    "f'{value:,}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'rule':['employee(.*)hurt(.*)hand', 'ip(.*)hurt(.*)hand']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb282727",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['status'] = test['rule'].apply(lambda x: check_presence(x, 'the ip hurt his right hand'))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw incident data\n",
    "incidents = pd.read_csv(\"data/source/20220413_D1_Incidents.csv\", dtype=str)  \n",
    "\n",
    "# Load the synonym dictionary in its raw csv format\n",
    "syn_csv = pd.read_csv('synonyms.csv')\n",
    "\n",
    "# Load the rule definitions\n",
    "rul_csv = pd.read_csv('rules.csv')\n",
    "\n",
    "# Concatenate some of the fields to make the 'text' field for searching\n",
    "incidents.rename(columns={'IncidentNumber': 'incident_id'}, inplace=True)\n",
    "incidents['text'] = (\n",
    "        incidents['ShortDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['FullDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['ImmediateAction'].astype(str).fillna('')\n",
    ").str.lower()\n",
    "\n",
    "# We only need the incident ID and the text for now\n",
    "incidents = incidents[['incident_id', 'text']]\n",
    "\n",
    "# Now convert the csv format into a dictionary of synonyms\n",
    "syn_dict = {}\n",
    "for r in range(len(syn_csv)):\n",
    "    syn_toks = syn_csv.keywords[r].split(',')\n",
    "    syn_dict.update({syn_csv.syn[r]:syn_toks})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357713d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rul_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker_syns, pain_syns, eye_syns\n",
    "worker_syns = ['employee', 'ip', 'worker', 'man', 'woman', 'he', 'she', 'his']\n",
    "pain_syns = ['pain', 'discomfort', 'soreness', 'hurt', 'something in', 'grit', 'swelling']\n",
    "eye_syns = ['eye', 'pupil', 'iris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85863d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [tok for tok in tokens if tok!='-']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bbd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_syns = tokenize(re.sub(r\", \", \" \", rul_csv.syns[0]))\n",
    "rul_syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dict.get(rul_syns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d9556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "c = 1\n",
    "\n",
    "patterns = []\n",
    "lhs = []\n",
    "rhs = []\n",
    "syn_count = len(rul_syns)\n",
    "\n",
    "for i in range(syn_count):\n",
    "    locals()[f'l{i+1}'] = syn_dict.get(rul_syns[i])\n",
    "\n",
    "iter_prod = itertools.product(l1, l2, l3)\n",
    "\n",
    "for r in iter_prod: \n",
    "    if syn_count == 2:\n",
    "        pt = f'{r[0].strip()}(.*){r[1].strip()}'\n",
    "    elif syn_count == 3:\n",
    "        pt = f'{r[0].strip()}(.*){r[1].strip()}(.*){r[2].strip()}'\n",
    "    else:\n",
    "        pt = f'{r[0].strip()}(.*){r[1].strip()}(.*){r[2].strip()}(.*){r[3].strip()}'\n",
    "    patterns.append(pt)\n",
    "    lhs.append(r[0].strip())\n",
    "    rhs.append(r[2].strip())\n",
    "    c += 1\n",
    "    \n",
    "test = pd.DataFrame({'pattern':patterns})    \n",
    "test['lhs'] = lhs\n",
    "test['rhs'] = rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ce32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_sent = 'the person hurt his right eye'\n",
    "sum(test['lhs'].apply(lambda x: find_index(chk_sent, x, pos='left')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38200a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_sent = 'the person hurt his right eye'\n",
    "split_chk_sent = chk_sent.split()\n",
    "print(split_chk_sent)\n",
    "test['found'] = test['pattern'].apply(lambda x: check_presence(x, chk_sent))\n",
    "test['lhs_index'] = test['lhs'].apply(lambda x: find_index(chk_sent, x, pos='left'))\n",
    "test['rhs_index'] = test['rhs'].apply(lambda x: find_index(chk_sent, x, pos='right'))\n",
    "test['span'] = test['rhs_index'] - test['lhs_index']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb31476",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['found'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92736a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['lhs_index'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_sent = 'the person hurt his right hurts eye'\n",
    "split_chk_sent = chk_sent.split()\n",
    "print(split_chk_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d62a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(chk_string, keyword, pos='left'):\n",
    "    try:\n",
    "        split_chk = chk_string.split()\n",
    "        #find_index = max(loc for loc, val in enumerate(split_chk) if val == keyword) + 1\n",
    "        find_index = [loc for loc, val in enumerate(split_chk) if bool(re.search(keyword, val))]\n",
    "        if pos == 'left':\n",
    "            find_index = min(find_index)+1\n",
    "        else:\n",
    "            find_index = max(find_index)+1\n",
    "    except:\n",
    "        print\n",
    "        find_index = 0\n",
    "    return(find_index)\n",
    "\n",
    "find_index(chk_sent, 'person', pos='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'leg'\n",
    "window = 2\n",
    "pre_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "post_context = \"<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "all_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "pre_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf874d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'My big fat leg is really broke'\n",
    "re.findall(pre_context, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(post_context, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c917fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"<keyword> how you doing\".replace('<keyword>', str(keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv('data/rule_book.csv')\n",
    "rules[\"keyword\"] = [x.replace(\"*\", \"[a-zA-Z'-]*\") + r\"\\b\" for x in rules[\"keyword\"]]\n",
    "rules[\"rules_pre\"] = [rbfuncts.translate_to_regex(x) for x in rules[\"rules_pre\"]]\n",
    "rules[\"rules_post\"] = [rbfuncts.translate_to_regex(x) for x in rules[\"rules_post\"]]\n",
    "rules[\"rules_all\"] = [rbfuncts.translate_to_regex(x) for x in rules[\"rules_all\"]]\n",
    "rules[\"voids\"] = [rbfuncts.translate_to_regex(x) for x in rules[\"voids\"]]\n",
    "categories = list(set(rules[\"group\"]))\n",
    "cat_dict = {cat: i for i, cat in enumerate(categories)}\n",
    "category_indicators = [False] * len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b24ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_presence(pattern, string):\n",
    "    if pattern:\n",
    "        return bool(re.search(pattern, string))\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a341a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern(doc, keyword, check_pre, check_post, check_all, check_void, window):\n",
    "    \"\"\"\n",
    "    for a list of tokens finds specified keyword and returns True\n",
    "    if the neighbourhood of this keyword satisfies pre-, post- or all- context rules\n",
    "    and doesn't contain anything forbidden\n",
    "    :param tokens: list of tokens\n",
    "    :param keyword: pattern which a token should match\n",
    "    :param check_pre: pattern which several previous tokens (concatenated) should match\n",
    "    :param check_post: pattern which several subsequent tokens (concatenated) should match\n",
    "    :param check_all: pattern which previous tokens + keyword + subsequent tokens should match\n",
    "    :param check_void: pattern which previous tokens + keyword + subsequent tokens should NOT match\n",
    "    :param window: N of pre and post tokens to consider\n",
    "    :return: True/False - whether at least one matching part was found\n",
    "    \"\"\"\n",
    "    # extract contexts of keyword (if any found)\n",
    "    # check if keyword in sentence\n",
    "    any_match = re.search(keyword, doc)\n",
    "\n",
    "    if any_match is None:\n",
    "        return False\n",
    "    else:\n",
    "        # We want to finad and extract the context of the keyword in the sentence\n",
    "        # With a predefined window\n",
    "        pre_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "        post_context = \"<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "        all_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "        \n",
    "        pre_match = re.findall(pre_context, doc)\n",
    "        post_match = re.findall(post_context, doc)\n",
    "        all_match = re.findall(all_context, doc)\n",
    "\n",
    "    # Check if any of the given sentences is on list of pre/post/all keywords.\n",
    "    pre_check = any([check_presence(check_pre, pre) for pre in pre_match])\n",
    "    post_check = any([check_presence(check_post, post) for post in post_match])\n",
    "    all_check = any([check_presence(check_all, all_) for all_ in all_match])\n",
    "    void_check = any([check_presence(check_void, all_) for all_ in all_match])\n",
    "\n",
    "    # Perform final tests\n",
    "    final_match = (pre_check or post_check or all_check) and not void_check\n",
    "    return final_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f88826",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rules = len(rules['group'])\n",
    "window = 12\n",
    "incidents = pd.read_csv(\"data/source/20220413_D1_Incidents.csv\", dtype=str)  \n",
    "# Concatenate some of the fields to make the 'text' field for searching\n",
    "incidents.rename(columns={'IncidentNumber': 'incident_id'}, inplace=True)\n",
    "incidents['text'] = (\n",
    "        incidents['ShortDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['FullDescription'].astype(str).fillna('') + ' ' + \n",
    "        incidents['ImmediateAction'].astype(str).fillna('')\n",
    ").str.lower()\n",
    "\n",
    "# We only need the incident ID and the text for now\n",
    "incidents = incidents[['incident_id', 'text']]\n",
    "sample100 = incidents.sample(100)\n",
    "doc=sample100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e120aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0333ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds = [\n",
    "        (\n",
    "            rules['group'][j],\n",
    "            find_pattern(\n",
    "                doc='employee’s hand was caught in between a flang. He then got in the car and drove into a deer',\n",
    "                keyword=rules[\"keyword\"][j],\n",
    "                check_pre=rules[\"rules_pre\"][j],\n",
    "                check_post=rules[\"rules_post\"][j],\n",
    "                check_all=rules[\"rules_all\"][j],\n",
    "                check_void=rules[\"voids\"][j],\n",
    "                window=window,\n",
    "            )\n",
    "        ) for j in range(num_rules)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b913b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list(filter(lambda x: x[1], finds))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cce73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list(set([x[0] for x in output]))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0acfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv('data/rule_book_kwic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03fcd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_regex(rule_part, syns_db):\n",
    "    \"\"\"\n",
    "    converts rule_book rules to regex format;\n",
    "    drops trailing separators in process\n",
    "    performs preprocessing to mutate synonyms & expand rule set for all permutations\n",
    "    \"\"\"\n",
    "    if isinstance(rule_part, str): # If rule part is a string...\n",
    "        \n",
    "        # 1st, we need to preprocess and mutate synonyms if they are found in rules\n",
    "        # 1st step is to split the rule set into individual rules\n",
    "        split_rule = rule_part.split('_ ')\n",
    "        # create an empty list to hold the mutates rule set\n",
    "        out_rule = []\n",
    "\n",
    "        for rule in split_rule:\n",
    "            # Check for presence of synonym, e.g., {eye}\n",
    "            syns = re.findall(\"{[a-zA-Z'-]*}\", rule)\n",
    "            # How many do we find?\n",
    "            syn_count = len(syns)\n",
    "            # No process based on how many we find (max number is 3, min is 0)\n",
    "            if syn_count == 1:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 1)\n",
    "                out_rule.append(syn_rules)\n",
    "            elif syn_count == 2:                \n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 2)\n",
    "                out_rule.append(syn_rules)\n",
    "            # elif syn_count == 3:                \n",
    "            #     syn_rules = mutate_syn(syns, syns_db, rule, 3)\n",
    "            #     out_rule.append(syn_rules)\n",
    "            else:       \n",
    "                # Do nothin, no mutation required as no synonym has been specified\n",
    "                out_rule.append(rule)\n",
    "                \n",
    "        # Join back to single rule set        \n",
    "        out_rule = '_ '.join(out_rule)\n",
    "        \n",
    "        # Now translate to regex\n",
    "        rule_part = re.sub(r\"\\s{2,}\", \" \", out_rule)\n",
    "        rule_part = re.sub(r'\\\\\\\\b', r'\\\\b', rule_part)\n",
    "        \n",
    "        return r'(\\b' + r'\\b)|(\\b'.join([s for s in rule_part.split('_ ') if s]) + r'\\b)'\n",
    "    else:\n",
    "        return '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e386ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns to regular expression. \n",
    "rules[\"keyword\"] = [x.replace(\"*\", \"[a-zA-Z'-]*\") + r\"\\b\" for x in rules[\"keyword\"]]\n",
    "rules[\"rules_pre\"] = [translate_to_regex(x) for x in rules[\"rules_pre\"]]\n",
    "rules[\"rules_post\"] = [translate_to_regex(x) for x in rules[\"rules_post\"]]\n",
    "rules[\"rules_all\"] = [translate_to_regex(x) for x in rules[\"rules_all\"]]\n",
    "rules[\"voids\"] = [translate_to_regex(x) for x in rules[\"voids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83161da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.iloc[28, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df37ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules['group'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(rules.group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2870348",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds = [\n",
    "        (\n",
    "            rules['group'][j],\n",
    "            find_pattern(\n",
    "                doc='pedestrian struck by forward-moving vehicle in roadway an employee stepped off the back of a truck and was struck by an oncoming vehicle. the employee suffered fractured ribs and bruised lungs and a fractured leg.',\n",
    "                keyword=rules[\"keyword\"][j],\n",
    "                check_pre=rules[\"rules_pre\"][j],\n",
    "                check_post=rules[\"rules_post\"][j],\n",
    "                check_all=rules[\"rules_all\"][j],\n",
    "                check_void=rules[\"voids\"][j],\n",
    "                window=12,\n",
    "            )\n",
    "        ) for j in range(len(rules))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = set(list(rules.group))\n",
    "for t in tmp:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7f65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[1], finds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cdf907",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.rules_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_presence(rules.rules_all[0], 'hello fp in the eye of the ip my')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_presence('(\\\\bfp.*eye.*ip\\\\b)', 'fp in the eye of the ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbd605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e215c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(re.search('(\\bfp.*eye.*ip\\b)', 'fp in the eye of the ip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c429406",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_to_regex(rules.rules_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.rules_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(re.search(\"{[a-zA-Z'-]*}\", rules.rules_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool(re.search(\"{[a-zA-Z'-]*}\", 'fp.*eye.*ip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037bb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"{[a-zA-Z'-]*}\", 'hello', 'fp.*eye.*{worker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "syns_db = pd.read_csv('synonyms.csv')\n",
    "syns_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_syns(in_str):\n",
    "    mod_str = re.sub('_syns', '', in_str) \n",
    "    return(mod_str)\n",
    "\n",
    "replace_syns('worker_syns')\n",
    "syns_db['syn'] = syns_db['syn'].apply(replace_syns)\n",
    "syns_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv('data/rule_book_test.csv')\n",
    "scan_rules = rules.rules_all[0].split('_ ')\n",
    "scan_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(\"{[a-zA-Z'-]*}\", '{spanner} in {eye}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d72e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_syn(syns, syns_db, rule, num):\n",
    "    syn_rules = []\n",
    "    if num == 1:    \n",
    "        syn_raw = syns[0]\n",
    "        syn = re.sub(r\"[\\([{})\\]]\", '', syn_raw)\n",
    "        found_syn = syns_db.loc[(syns_db['syn'] == syn)]\n",
    "        for keyword in found_syn.iloc[0, 1].split(', '):\n",
    "            syn_rules.append(re.sub(syn_raw, keyword, rule))\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)\n",
    "    elif num == 2:\n",
    "        syn_raw_1 = syns[0]\n",
    "        syn_1 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_1)\n",
    "        found_syn_1 = syns_db.loc[(syns_db['syn'] == syn_1)]\n",
    "\n",
    "        syn_raw_2 = syns[1]\n",
    "        syn_2 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_2)\n",
    "        found_syn_2 = syns_db.loc[(syns_db['syn'] == syn_2)]\n",
    "\n",
    "        for keyword_1 in found_syn_1.iloc[0, 1].split(', '):\n",
    "            for keyword_2 in found_syn_2.iloc[0, 1].split(', '):\n",
    "                pass_1 = re.sub(syn_raw_1, keyword_1, rule)\n",
    "                pass_2 = re.sub(syn_raw_2, keyword_2, pass_1)\n",
    "                syn_rules.append(pass_2)\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)\n",
    "    elif num == 3:\n",
    "        syn_raw_1 = syns[0]\n",
    "        syn_1 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_1)\n",
    "        found_syn_1 = syns_db.loc[(syns_db['syn'] == syn_1)]\n",
    "\n",
    "        syn_raw_2 = syns[1]\n",
    "        syn_2 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_2)\n",
    "        found_syn_2 = syns_db.loc[(syns_db['syn'] == syn_2)]\n",
    "\n",
    "        syn_raw_3 = syns[2]\n",
    "        syn_3 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_3)\n",
    "        found_syn_3 = syns_db.loc[(syns_db['syn'] == syn_3)]\n",
    "\n",
    "        for keyword_1 in found_syn_1.iloc[0, 1].split(', '):\n",
    "            for keyword_2 in found_syn_2.iloc[0, 1].split(', '):\n",
    "                for keyword_3 in found_syn_3.iloc[0, 1].split(', '):\n",
    "                    pass_1 = re.sub(syn_raw_1, keyword_1, rule)\n",
    "                    pass_2 = re.sub(syn_raw_2, keyword_2, pass_1)\n",
    "                    pass_3 = re.sub(syn_raw_3, keyword_3, pass_2)\n",
    "                    syn_rules.append(pass_3)\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fadd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_rules = rules.rules_all[0].split('_ ')\n",
    "out_rules = []\n",
    "\n",
    "for rule in scan_rules:\n",
    "    syns = re.findall(\"{[a-zA-Z'-]*}\", rule)\n",
    "    syn_count = len(syns)\n",
    "    if syn_count == 1:\n",
    "        syn_rules = mutate_syn(syns, syns_db, rule, 1)\n",
    "        out_rules.append(syn_rules)\n",
    "    elif syn_count == 2:\n",
    "        syn_rules = mutate_syn(syns, syns_db, rule, 2)\n",
    "        out_rules.append(syn_rules)\n",
    "    elif syn_count == 3:\n",
    "        syn_rules = mutate_syn(syns, syns_db, rule, 3)\n",
    "        out_rules.append(syn_rules)\n",
    "    else:       \n",
    "        out_rules.append(rule)\n",
    "out_rules = '_ '.join(out_rules)\n",
    "print(out_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_regex(rule_part, syns_db):\n",
    "    \"\"\"\n",
    "    converts rule_book rules to regex format;\n",
    "    drops trailing separators in process\n",
    "    \"\"\"\n",
    "    if isinstance(rule_part, str): # If rule part is a string...\n",
    "        \n",
    "        split_rule = rule_part.split('_ ')\n",
    "        out_rule = []\n",
    "\n",
    "        for rule in split_rule:\n",
    "            syns = re.findall(\"{[a-zA-Z'-]*}\", rule)\n",
    "            syn_count = len(syns)\n",
    "            if syn_count == 1:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 1)\n",
    "                out_rule.append(syn_rules)\n",
    "            elif syn_count == 2:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 2)\n",
    "                out_rule.append(syn_rules)\n",
    "            elif syn_count == 3:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 3)\n",
    "                out_rule.append(syn_rules)\n",
    "            else:       \n",
    "                out_rule.append(rule)\n",
    "        out_rule = '_ '.join(out_rule)\n",
    "        \n",
    "        rule_part = re.sub(r\"\\s{2,}\", \" \", out_rule)\n",
    "        rule_part = re.sub(r'\\\\\\\\b', r'\\\\b', rule_part)\n",
    "        \n",
    "        return r'(\\b' + r'\\b)|(\\b'.join([s for s in rule_part.split('_ ') if s]) + r'\\b)'\n",
    "    else:\n",
    "        return '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = translate_to_regex(rules.rules_all[0], syns_db)\n",
    "chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_presence(chk, 'An fp was lodged in the left eye of the new technician.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ad356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "load_cases = []\n",
    "for r in itertools.product(['hell', 'butts'], ['me', 'you','them']): \n",
    "    lc = f'{r[0]}.*{r[1]}'\n",
    "    load_cases.append(lc)\n",
    "load_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f30b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rule = translate_to_regex(syn_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82397d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_presence(test_rule, 'hello fp in the eye of the operator of the ip my')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_incs = pd.read_csv(\"data/source/OSHA_January2015toJuly2021.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_incs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb53b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_incs['Final Narrative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c443a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate some of the fields to make the 'text' field for searching\n",
    "osha_incs.rename(columns={'ID': 'incident_id'}, inplace=True)\n",
    "osha_incs['text'] = (\n",
    "        osha_incs['EventTitle'].astype(str).fillna('') + ' ' + \n",
    "        osha_incs['Final Narrative'].astype(str).fillna('')\n",
    ").str.lower()\n",
    "osha_incs['dataset'] = 'OSHA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6174d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "osha_incs = osha_incs[['incident_id', 'dataset', 'text']]\n",
    "osha_incs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aabbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv('data/rule_book_kwic.csv')\n",
    "focus_group = 'competency'\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rules = rules.loc[(rules['group'] == focus_group)]\n",
    "filter_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ea4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'bag'\n",
    "window = 5\n",
    "doc = 'this is a big bag of shoes. big bags and a second huge back pack bag of rocks'\n",
    "pre_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>\".replace('<keyword>', str(keyword)).replace('<window>', str(window))      \n",
    "pre_match = re.findall(pre_context, doc)\n",
    "pre_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598574f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_toks = sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_list = sent_tokenize(doc)\n",
    "tok_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [re.findall(pre_context, t) for t in tok_list]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(list_of_lists):\n",
    "    return [x for xs in list_of_lists for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a9aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten([re.findall(pre_context, t) for t in tok_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02433e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "syns_data = pd.read_csv('synonyms.csv')\n",
    "syns_data['syn'] = syns_data['syn'].apply(rbfuncts.replace_syns)\n",
    "syns_db = syns_data\n",
    "syns_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_regex(rule_part, syns_db):\n",
    "    \"\"\"\n",
    "    converts rule_book rules to regex format;\n",
    "    drops trailing separators in process\n",
    "    performs preprocessing to mutate synonyms & expand rule set for all permutations\n",
    "    \"\"\"\n",
    "    if isinstance(rule_part, str): # If rule part is a string...\n",
    "        \n",
    "        # 1st, we need to preprocess and mutate synonyms if they are found in rules\n",
    "        # 1st step is to split the rule set into individual rules\n",
    "        split_rule = rule_part.split('_ ')\n",
    "        # create an empty list to hold the mutates rule set\n",
    "        out_rule = []\n",
    "\n",
    "        for rule in split_rule:\n",
    "            \n",
    "            # Check for presence of synonym, e.g., {eye}\n",
    "            syns = re.findall(\"{[a-zA-Z'-]*}\", rule)\n",
    "            # How many do we find?\n",
    "            syn_count = len(syns)\n",
    "            # No process based on how many we find (max number is 3, min is 0)\n",
    "            if syn_count == 1:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 1)\n",
    "                out_rule.append(syn_rules)\n",
    "            elif syn_count == 2:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 2)\n",
    "                out_rule.append(syn_rules)\n",
    "            elif syn_count == 3:\n",
    "                syn_rules = mutate_syn(syns, syns_db, rule, 3)\n",
    "                out_rule.append(syn_rules)\n",
    "            else:       \n",
    "                # Do nothin, no mutation required as no synonym has been specified\n",
    "                out_rule.append(rule)\n",
    "                \n",
    "        # Join back to single rule set        \n",
    "        out_rule = '_ '.join(out_rule)\n",
    "        \n",
    "        # Now translate to regex\n",
    "        rule_part = re.sub(r\"\\s{2,}\", \" \", out_rule)\n",
    "        rule_part = re.sub(r'\\\\\\\\b', r'\\\\b', rule_part)\n",
    "        print(r'(\\b' + r'\\b)|(\\b'.join([s for s in rule_part.split('_ ') if s]) + r'\\b)')\n",
    "        return r'(\\b' + r'\\b)|(\\b'.join([s for s in rule_part.split('_ ') if s]) + r'\\b)'\n",
    "    else:\n",
    "        return '' \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1106c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_syn(syns, syns_db, rule, num):\n",
    "    syn_rules = []\n",
    "    if num == 1:    \n",
    "        syn_raw = syns[0]\n",
    "        syn = re.sub(r\"[\\([{})\\]]\", '', syn_raw)\n",
    "        found_syn = syns_db.loc[(syns_db['syn'] == syn)]\n",
    "        for keyword in found_syn.iloc[0, 1].split(', '):\n",
    "            syn_rules.append(re.sub(syn_raw, keyword, rule))\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)\n",
    "    elif num == 2:\n",
    "        syn_raw_1 = syns[0]\n",
    "        syn_1 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_1)\n",
    "        found_syn_1 = syns_db.loc[(syns_db['syn'] == syn_1)]\n",
    "\n",
    "        syn_raw_2 = syns[1]\n",
    "        syn_2 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_2)\n",
    "        found_syn_2 = syns_db.loc[(syns_db['syn'] == syn_2)]\n",
    "\n",
    "        for keyword_1 in found_syn_1.iloc[0, 1].split(', '):\n",
    "            for keyword_2 in found_syn_2.iloc[0, 1].split(', '):\n",
    "                pass_1 = re.sub(syn_raw_1, keyword_1, rule)\n",
    "                pass_2 = re.sub(syn_raw_2, keyword_2, pass_1)\n",
    "                syn_rules.append(pass_2)\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)\n",
    "    elif num == 3:\n",
    "        syn_raw_1 = syns[0]\n",
    "        syn_1 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_1)\n",
    "        found_syn_1 = syns_db.loc[(syns_db['syn'] == syn_1)]\n",
    "\n",
    "        syn_raw_2 = syns[1]\n",
    "        syn_2 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_2)\n",
    "        found_syn_2 = syns_db.loc[(syns_db['syn'] == syn_2)]\n",
    "\n",
    "        syn_raw_3 = syns[2]\n",
    "        syn_3 = re.sub(r\"[\\([{})\\]]\", '', syn_raw_3)\n",
    "        found_syn_3 = syns_db.loc[(syns_db['syn'] == syn_3)]\n",
    "\n",
    "        for keyword_1 in found_syn_1.iloc[0, 1].split(', '):\n",
    "            for keyword_2 in found_syn_2.iloc[0, 1].split(', '):\n",
    "                for keyword_3 in found_syn_3.iloc[0, 1].split(', '):\n",
    "                    pass_1 = re.sub(syn_raw_1, keyword_1, rule)\n",
    "                    pass_2 = re.sub(syn_raw_2, keyword_2, pass_1)\n",
    "                    pass_3 = re.sub(syn_raw_3, keyword_3, pass_2)\n",
    "                    syn_rules.append(pass_3)\n",
    "        syn_rules = '_ '.join(syn_rules)\n",
    "        return(syn_rules)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[\"rules_all\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_all\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[\"voids\"] = [translate_to_regex(x, syns_db) for x in rules[\"voids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b56891",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[\"voids\"][139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b30cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '(\\\\bman .* dirt .* eye\\\\b)'\n",
    "rbfuncts.check_presence(pattern, 'the man got some dirt in his eye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3384873",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = 'slips'\n",
    "tmp2 = 'bad'\n",
    "tmp1 == tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'struck by falling object or equipment, n.e.c. on october 26, 2016, at 12:00 p.m., an employee was using a pry-bar to raise the manholes to the level of the new pavement. the manhole cover slipped off of the pry-bar as he was reaching under the manhole cover and crushed the tip of his left middle finger. the tip of his left middle finger with some bone was amputated at the hospital.'\n",
    "sen_toks = sent_tokenize(doc)\n",
    "sen_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ada44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "check_all = rules[\"rules_all\"][138]\n",
    "len(check_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f157ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(check_all.split('|'), columns=['pattern'])\n",
    "tmp['doc'] = 'on october 26, 2016, at 12:00 p.m., an employee was using a pry-bar to raise the manholes to the level of the new pavement.'\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame()\n",
    "for all_ in sen_toks:\n",
    "    tmp_add = pd.DataFrame(check_all.split('|'), columns=['pattern'])\n",
    "    tmp_add['doc'] = all_\n",
    "    tmp = pd.concat([tmp, tmp_add])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7878eb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "find = False\n",
    "tic = int(round(time.time() * 1000))\n",
    "for all_ in sen_toks:\n",
    "    df_scan = pd.DataFrame(check_all.split('|'), columns=['pattern'])\n",
    "    df_scan['doc'] = all_\n",
    "    df_scan['finds'] = df_scan[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)\n",
    "    #df_scan['finds'] = df_scan.apply(lambda x: check_presence(x.pattern, x.doc), axis=1)\n",
    "    find = bool(sum(df_scan['finds'])) or find  \n",
    "    if find: break\n",
    "print(f'Time taken: {int(round(time.time() * 1000)) - tic} ms')    \n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_void = rules[\"voids\"][1]\n",
    "check_void"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_void.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32549a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'my contractor suffered an abrasion to his ankle. and was struck by falling object or equipment, n.e.c. on october 26, 2016, at 12:00 p.m., an employee was using a pry-bar to raise the manholes to the level of the new pavement. the manhole cover slipped off of the pry-bar as he was reaching under the manhole cover and crushed the tip of his left middle finger. the tip of his left middle finger with some bone was amputated at the hospital.'\n",
    "sen_toks = sent_tokenize(doc)\n",
    "sen_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "void = False\n",
    "for all_ in sen_toks:\n",
    "    df_scan = pd.DataFrame(check_all.split('|'), columns=['pattern'])    \n",
    "    df_scan['doc'] = all_\n",
    "    df_scan['finds'] = df_scan[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)    \n",
    "    #df_scan['finds'] = df_scan.apply(lambda x: check_presence(x.pattern, x.doc), axis=1)\n",
    "    find = bool(sum(df_scan['finds']))\n",
    "    if len(check_void) != 0:\n",
    "        df_void = pd.DataFrame(check_void.split('|'), columns=['pattern'])\n",
    "        df_void['doc'] = all_\n",
    "        df_void['voids'] = df_void[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)\n",
    "        void = bool(sum(df_void['voids']))\n",
    "    final_match = find and not void    \n",
    "    if final_match: break\n",
    "final_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe68ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any([check_presence(check_pre, pre) for pre in pre_match])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_apply(sens, rules):\n",
    "    if len(rules) != 0:\n",
    "        for all_ in sens:\n",
    "            print(all_)\n",
    "            df_scan = pd.DataFrame(rules.split('|'), columns=['pattern'])    \n",
    "            df_scan['doc'] = all_\n",
    "            df_scan['finds'] = df_scan[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)    \n",
    "            find = bool(sum(df_scan['finds']))       \n",
    "            if find: break\n",
    "    else:\n",
    "        find = False\n",
    "    print(find)    \n",
    "    return(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69420297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_apply(sen, rules):\n",
    "    if len(rules) != 0:\n",
    "        df_scan = pd.DataFrame(rules.split('|'), columns=['pattern'])    \n",
    "        df_scan['doc'] = sen\n",
    "        df_scan['finds'] = df_scan[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)    \n",
    "        find = bool(sum(df_scan['finds']))       \n",
    "    else:\n",
    "        find = False   \n",
    "    return(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_apply_all(sens, check_pre, check_post, check_all, check_void):\n",
    "    for sen in sens:\n",
    "        pre_check, post_check, all_check, void_check = False, False, False, False\n",
    "        if len(check_pre) != 0:\n",
    "            pre_check = check_apply(sen, check_pre)\n",
    "        if len(check_post) != 0:\n",
    "            post_check = check_apply(sen, check_post)\n",
    "        if len(check_all) != 0:\n",
    "            all_check = check_apply(sen, check_all)\n",
    "        if len(check_void) != 0:\n",
    "            void_check = check_apply(sen, check_void)    \n",
    "\n",
    "        final_match = (pre_check or post_check or all_check) and not void_check\n",
    "        print(final_match)\n",
    "        if final_match: break\n",
    "    return(final_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e4e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_apply_all(sen_toks, check_pre=check_all, check_post=check_all, check_all=check_all, check_void=check_void)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd28756",
   "metadata": {},
   "outputs": [],
   "source": [
    "True and not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7217fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_apply(sen_toks, check_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c965ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_apply(sen_toks, check_void)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['finds'] = tmp.apply(lambda x: check_presence(x.pattern, x.doc), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tmp['finds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4519fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['finds'] = tmp[['pattern', 'doc']].apply(lambda x: check_presence(*x), axis=1)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "finds = []\n",
    "for i in range(len(tmp)):\n",
    "    finds.append(check_presence(tmp['pattern'][i],tmp['doc'][i]))\n",
    "sum(finds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf796c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_check = any([check_presence(check_all, all_) for all_ in sen_toks])\n",
    "void_check = False\n",
    "#void_check = any([check_presence(check_void, all_) for all_ in sen_toks])\n",
    "final_match = all_check and not void_check\n",
    "final_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for all_ in sen_toks:\n",
    "    print(all_)\n",
    "    print(check_presence(check_all, all_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db120c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pd.read_csv('data/rule_book_kwic.csv')\n",
    "rules[\"keyword\"] = [x.replace(\"*\", \"[a-zA-Z'-]*\") + r\"\\b\" for x in rules[\"keyword\"]]\n",
    "rules[\"rules_pre\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_pre\"]]\n",
    "rules[\"rules_post\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_post\"]]\n",
    "rules[\"rules_all\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_all\"]]\n",
    "rules[\"voids\"] = [translate_to_regex(x, syns_db) for x in rules[\"voids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.loc[(rules.group == 'general illness or health issue')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 224\n",
    "keyword=rules[\"keyword\"][i]\n",
    "check_pre=rules[\"rules_pre\"][i]\n",
    "check_post=rules[\"rules_post\"][i]\n",
    "check_all=rules[\"rules_all\"][i]\n",
    "check_void=rules[\"voids\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf32d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword = \"collap[a-zA-Z'-]*\\b\"\n",
    "#keyword = \"collapsed\"\n",
    "window = 12\n",
    "pre_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "post_context = \"<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))\n",
    "all_context = \"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,<window>}<keyword>(?:[^a-zA-Z'-]+[a-zA-Z'-]+){0,<window>}\".replace('<keyword>', str(keyword)).replace('<window>', str(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97039664",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b8e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d50a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'ip collapsed while walking on the airplane from the bathroom. my contractor suffered an abrasion to his ankle. and was struck by falling object or equipment, n.e.c. on october 26, 2016, at 12:00 p.m., an employee was using a pry-bar to raise the manholes to the level of the new pavement. the manhole cover slipped off of the pry-bar as he was reaching under the manhole cover and crushed the tip of his left middle finger. the tip of his left middle finger with some bone was amputated at the hospital.'\n",
    "sen_toks = sent_tokenize(doc)\n",
    "sen_toks\n",
    "pre_match = flatten([re.findall(pre_context, t) for t in sen_toks]) \n",
    "post_match = flatten([re.findall(post_context, t) for t in sen_toks])\n",
    "all_match = flatten([re.findall(all_context, t) for t in sen_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52376676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5695e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8925d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f087b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_apply_all(sens_pre, sens_post, sens_all, check_pre, check_post, check_all, check_void):\n",
    "    pre_check, post_check, all_check, void_check = False, False, False, False\n",
    "    for sen in sens_pre:\n",
    "        pre_check = False\n",
    "        if len(check_pre) != 0:\n",
    "            pre_check = check_apply(sen, check_pre)\n",
    "            if pre_check: break\n",
    "            \n",
    "    for sen in sens_post:\n",
    "        post_check = False        \n",
    "        if len(check_post) != 0:\n",
    "            post_check = check_apply(sen, check_post)\n",
    "            if post_check: break\n",
    "            \n",
    "    for sen in sens_all:    \n",
    "        all_check, void_check = False, False   \n",
    "        if len(check_all) != 0:\n",
    "            all_check = check_apply(sen, check_all)\n",
    "        if len(check_void) != 0:\n",
    "            void_check = check_apply(sen, check_void)   \n",
    "            if void_check: break \n",
    "\n",
    "    final_match = (pre_check or post_check or all_check) and not void_check\n",
    "        \n",
    "    return(final_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_apply_all(\n",
    "            sens_pre=pre_match, \n",
    "            sens_post=post_match, \n",
    "            sens_all=all_match, \n",
    "            check_pre=check_pre, \n",
    "            check_post=check_post, \n",
    "            check_all=check_all, \n",
    "            check_void=check_void\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [5, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents.sample(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9de623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738458a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score in [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_score_check = 0\n",
    "while valid_score_check != 1:\n",
    "    print('******')\n",
    "    score = int(input('Score (1: Good, 2: Fair, 3: Poor): '))\n",
    "    score_check = score in [1, 2, 3]\n",
    "    print(score_check)\n",
    "    if score_check: valid_score_check = 1\n",
    "    print(valid_score_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "while i < 6:\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c41115",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents['text'][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6756bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ref = '220730103309'\n",
    "out_df = pd.read_csv(f\"test_samples/{sample_ref}_100_sample_scores.csv\", dtype=str)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f05b1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>dset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hand or arm injury</td>\n",
       "      <td>injured by slipping or swinging object held by...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid</td>\n",
       "      <td>one member of contractor project team tested p...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slips &amp; trips, hand or arm injury, dropped obj...</td>\n",
       "      <td>other fall to lower level, unspecified an empl...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hand or arm injury, lifting or moving loads</td>\n",
       "      <td>struck against moving part of machinery or equ...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hand or arm injury</td>\n",
       "      <td>caught in running equipment or machinery durin...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>fire</td>\n",
       "      <td>a small electric powered diesel fired space he...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>competency</td>\n",
       "      <td>A subcontractor working under direct supervisi...</td>\n",
       "      <td>MANF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bites (animals or insects)</td>\n",
       "      <td>worker stung on face by bee.  no treatment cas...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>dropped object or material</td>\n",
       "      <td>During the inspection of the south S356 turbin...</td>\n",
       "      <td>MANF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>theft, vehicle incident general</td>\n",
       "      <td>company vehicle was broken into and tools were...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             category  \\\n",
       "0                                  hand or arm injury   \n",
       "1                                               covid   \n",
       "2   slips & trips, hand or arm injury, dropped obj...   \n",
       "3         hand or arm injury, lifting or moving loads   \n",
       "4                                  hand or arm injury   \n",
       "..                                                ...   \n",
       "95                                               fire   \n",
       "96                                         competency   \n",
       "97                         bites (animals or insects)   \n",
       "98                         dropped object or material   \n",
       "99                    theft, vehicle incident general   \n",
       "\n",
       "                                                 text  dset  \n",
       "0   injured by slipping or swinging object held by...  OSHA  \n",
       "1   one member of contractor project team tested p...  ORGP  \n",
       "2   other fall to lower level, unspecified an empl...  OSHA  \n",
       "3   struck against moving part of machinery or equ...  OSHA  \n",
       "4   caught in running equipment or machinery durin...  OSHA  \n",
       "..                                                ...   ...  \n",
       "95  a small electric powered diesel fired space he...  ORGP  \n",
       "96  A subcontractor working under direct supervisi...  MANF  \n",
       "97  worker stung on face by bee.  no treatment cas...  ORGP  \n",
       "98  During the inspection of the south S356 turbin...  MANF  \n",
       "99  company vehicle was broken into and tools were...  ORGP  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd46485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kwic_rule_book_scan(rules, docs, syns_db, run_rules='all', verb = False): \n",
    "\n",
    "    # Transform columns to regular expression. \n",
    "    rules[\"keyword\"] = [x.replace(\"*\", \"[a-zA-Z'-]*\") + r\"\\b\" for x in rules[\"keyword\"]]\n",
    "    rules[\"rules_pre\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_pre\"]]\n",
    "    rules[\"rules_post\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_post\"]]\n",
    "    rules[\"rules_all\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_all\"]]\n",
    "    rules[\"voids\"] = [translate_to_regex(x, syns_db) for x in rules[\"voids\"]]\n",
    "    #rules.to_csv('rules_out_temp.csv')\n",
    "    # Clean all texts from request\n",
    "    categories = [categorize_text(doc, rules, window = 12, focus_group=run_rules, verbose=verb) for doc in tqdm(docs)]\n",
    "    return (categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a89daea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>keyword</th>\n",
       "      <th>rules_pre</th>\n",
       "      <th>rules_post</th>\n",
       "      <th>rules_all</th>\n",
       "      <th>voids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slips &amp; trips</td>\n",
       "      <td>slip[a-zA-Z'-]*\\b</td>\n",
       "      <td>walking (.*) snow_ walking (.*) ice_ walking (...</td>\n",
       "      <td>fall_ fell_ went over_ hurt.*_ and twist.*_ to...</td>\n",
       "      <td>(\\bslip.*fall\\b)|(\\bslip.*fell\\b)|(\\bslip.*twi...</td>\n",
       "      <td>fell (.*) bike_ no slip_ no fall_ it slipped_ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>slips &amp; trips</td>\n",
       "      <td>trip[a-zA-Z'-]*\\b</td>\n",
       "      <td>walking (.*) snow_ walking (.*) ice_ walking (...</td>\n",
       "      <td>fall_ fell_ went over_ frayed_ loose_ hazard__...</td>\n",
       "      <td>(\\bfall\\b)|(\\bfell\\b)|(\\btrip\\b)|(\\btripped\\b)...</td>\n",
       "      <td>fell (.*) bike_ no slip_ no fall_ it slipped_ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slips &amp; trips</td>\n",
       "      <td>stumble[a-zA-Z'-]*\\b</td>\n",
       "      <td>causing.*cleaner to_ causing.*ip to_ causing.*...</td>\n",
       "      <td>floor_ and twist.*</td>\n",
       "      <td>(\\bhurting foot\\b)</td>\n",
       "      <td>rung.*step.*_ while sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slips &amp; trips</td>\n",
       "      <td>uneven\\b</td>\n",
       "      <td>causing.*cleaner to_ causing.*ip to_ causing.*...</td>\n",
       "      <td>_ and twist.*</td>\n",
       "      <td>(\\bemployee.* uneven.* surface\\b)|(\\bip.* unev...</td>\n",
       "      <td>rung.*step.*_ while sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slips &amp; trips</td>\n",
       "      <td>fell\\b</td>\n",
       "      <td>causing.*cleaner to_ causing.*ip to_ causing.*...</td>\n",
       "      <td>_ and twist.*_ on.*floor_ on.*ground</td>\n",
       "      <td>(\\bemployee fell back.*\\b)|(\\bip fell back.*\\b...</td>\n",
       "      <td>straps_ drop.*_ fell (.*) bike_ no slip_ no fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>vandalism</td>\n",
       "      <td>sever[a-zA-Z'-]*\\b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\\bintentionally.*sever.*others\\b)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>line of fire</td>\n",
       "      <td>pressure\\b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\\btight.*under.*pressure_tight.*while.*pressu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>line of fire</td>\n",
       "      <td>line\\b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\\bline of fire\\b)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>line of fire</td>\n",
       "      <td>release\\b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\\baccidental.*release.*pressure\\b)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>near miss</td>\n",
       "      <td>near\\b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(\\bnear miss\\b)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             group               keyword  \\\n",
       "0    slips & trips     slip[a-zA-Z'-]*\\b   \n",
       "1    slips & trips     trip[a-zA-Z'-]*\\b   \n",
       "2    slips & trips  stumble[a-zA-Z'-]*\\b   \n",
       "3    slips & trips              uneven\\b   \n",
       "4    slips & trips                fell\\b   \n",
       "..             ...                   ...   \n",
       "364      vandalism    sever[a-zA-Z'-]*\\b   \n",
       "365   line of fire            pressure\\b   \n",
       "366   line of fire                line\\b   \n",
       "367   line of fire             release\\b   \n",
       "368      near miss                near\\b   \n",
       "\n",
       "                                             rules_pre  \\\n",
       "0    walking (.*) snow_ walking (.*) ice_ walking (...   \n",
       "1    walking (.*) snow_ walking (.*) ice_ walking (...   \n",
       "2    causing.*cleaner to_ causing.*ip to_ causing.*...   \n",
       "3    causing.*cleaner to_ causing.*ip to_ causing.*...   \n",
       "4    causing.*cleaner to_ causing.*ip to_ causing.*...   \n",
       "..                                                 ...   \n",
       "364                                                NaN   \n",
       "365                                                NaN   \n",
       "366                                                NaN   \n",
       "367                                                NaN   \n",
       "368                                                NaN   \n",
       "\n",
       "                                            rules_post  \\\n",
       "0    fall_ fell_ went over_ hurt.*_ and twist.*_ to...   \n",
       "1    fall_ fell_ went over_ frayed_ loose_ hazard__...   \n",
       "2                                   floor_ and twist.*   \n",
       "3                                        _ and twist.*   \n",
       "4                 _ and twist.*_ on.*floor_ on.*ground   \n",
       "..                                                 ...   \n",
       "364                                                NaN   \n",
       "365                                                NaN   \n",
       "366                                                NaN   \n",
       "367                                                NaN   \n",
       "368                                                NaN   \n",
       "\n",
       "                                             rules_all  \\\n",
       "0    (\\bslip.*fall\\b)|(\\bslip.*fell\\b)|(\\bslip.*twi...   \n",
       "1    (\\bfall\\b)|(\\bfell\\b)|(\\btrip\\b)|(\\btripped\\b)...   \n",
       "2                                   (\\bhurting foot\\b)   \n",
       "3    (\\bemployee.* uneven.* surface\\b)|(\\bip.* unev...   \n",
       "4    (\\bemployee fell back.*\\b)|(\\bip fell back.*\\b...   \n",
       "..                                                 ...   \n",
       "364                 (\\bintentionally.*sever.*others\\b)   \n",
       "365  (\\btight.*under.*pressure_tight.*while.*pressu...   \n",
       "366                                 (\\bline of fire\\b)   \n",
       "367                (\\baccidental.*release.*pressure\\b)   \n",
       "368                                    (\\bnear miss\\b)   \n",
       "\n",
       "                                                 voids  \n",
       "0    fell (.*) bike_ no slip_ no fall_ it slipped_ ...  \n",
       "1    fell (.*) bike_ no slip_ no fall_ it slipped_ ...  \n",
       "2                          rung.*step.*_ while sitting  \n",
       "3                          rung.*step.*_ while sitting  \n",
       "4    straps_ drop.*_ fell (.*) bike_ no slip_ no fa...  \n",
       "..                                                 ...  \n",
       "364                                                NaN  \n",
       "365                                                NaN  \n",
       "366                                                NaN  \n",
       "367                                                NaN  \n",
       "368                                                NaN  \n",
       "\n",
       "[369 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = pd.read_csv('data/rule_book_kwic.csv')\n",
    "\n",
    "syns_data = pd.read_csv('synonyms.csv')\n",
    "syns_data['syn'] = syns_data['syn'].apply(rbfuncts.replace_syns)\n",
    "syns_db = syns_data\n",
    "\n",
    "rules[\"keyword\"] = [x.replace(\"*\", \"[a-zA-Z'-]*\") + r\"\\b\" for x in rules[\"keyword\"]]\n",
    "rules[\"rules_all\"] = [translate_to_regex(x, syns_db) for x in rules[\"rules_all\"]]\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4bedc618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 101.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the synonym database\n",
    "syns_data = pd.read_csv('synonyms.csv')\n",
    "syns_data['syn'] = syns_data['syn'].apply(rbfuncts.replace_syns)\n",
    "        \n",
    "#doc_test = 'injured by slipping or swinging object held by injured worker an employee was cutting sheets of cotton batting with a lightweight round knife. the knife cut his left middle finger, causing the amputation of flesh from the fingertip.'\n",
    "doc_test = out_df[\"text\"]\n",
    "rul_csv = pd.read_csv('data/rule_book_kwic.csv')\n",
    "categories = rbfuncts.kwic_rule_book_scan(\n",
    "        rules=rul_csv, \n",
    "        docs=doc_test, syns_db=syns_data, run_rules='lifting or moving loads', verb=False\n",
    ")\n",
    "\n",
    "# Now tidy up the presentation of the output for printing\n",
    "cats = []\n",
    "for entry in categories:\n",
    "        if ', '.join(entry) == '':\n",
    "                cats.append('*** Not Classified') # So as to easily identify unclassified texts\n",
    "        else:                \n",
    "                cats.append(', '.join(entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "311b9a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(\\\\bmoving.*with.*skid\\\\b)|(\\\\bwhil.*moving.*stone\\\\b)|(\\\\bdamaged.*while.*mov.*materials\\\\b)|(\\\\bwhile moving scaffold\\\\b)']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = rules[rules['keyword'] == 'moving\\\\b']\n",
    "list(tmp['rules_all'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "104620f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oil leak from_ underground_ table saw']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tmp['voids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "670e7437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(4, 9), match='knife'>\n"
     ]
    }
   ],
   "source": [
    "doc_test = 'the knife dsddcut his left middle finger, causing the amputation of flesh from the fingertip.'\n",
    "any_match = re.search('knife\\\\b', doc_test)\n",
    "print(any_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92f04825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pattern = '(knife cut his)'\n",
    "rbfuncts.check_presence(chk_rule, doc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b0e46247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>dset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>other fall to lower level, unspecified an empl...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>attempted break in of wgpsn vehicle outside em...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>Employee partially fell through rooflight whil...</td>\n",
       "      <td>MANF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>other fall to lower level less than 6 feet an ...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>an employee received a splinter to the hand fr...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>injury to right hand  ip was in the mess hall ...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>2 workers was confirmed as covid-19 infection....</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>IP suffered tendon injury to his right shoulde...</td>\n",
       "      <td>MANF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>Worker broke leg when he became partially trap...</td>\n",
       "      <td>MANF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>lower back pain while carrying buckets employe...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>the sub-contractor employee was working more t...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>thrown, fell, or jumped from animal being ridd...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lifting or moving loads</td>\n",
       "      <td>the drillers struck 12-inch sewer line coming ...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>other fall to lower level 26 to 30 feet a temp...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lifting or moving loads</td>\n",
       "      <td>struck against moving part of machinery or equ...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>climbing or stepping up or down-single episode...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>ee tested positive for covid-19 ee tested posi...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lifting or moving loads</td>\n",
       "      <td>boom of awp came in contact with materials sto...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>other fall to lower level, unspecified an empl...</td>\n",
       "      <td>OSHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>*** Not Classified</td>\n",
       "      <td>employee was performing work inside unit witho...</td>\n",
       "      <td>ORGP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category  \\\n",
       "15       *** Not Classified   \n",
       "16       *** Not Classified   \n",
       "17       *** Not Classified   \n",
       "18       *** Not Classified   \n",
       "19       *** Not Classified   \n",
       "20       *** Not Classified   \n",
       "21       *** Not Classified   \n",
       "22       *** Not Classified   \n",
       "23       *** Not Classified   \n",
       "24       *** Not Classified   \n",
       "25       *** Not Classified   \n",
       "26       *** Not Classified   \n",
       "27  lifting or moving loads   \n",
       "28       *** Not Classified   \n",
       "29  lifting or moving loads   \n",
       "30       *** Not Classified   \n",
       "31       *** Not Classified   \n",
       "32  lifting or moving loads   \n",
       "33       *** Not Classified   \n",
       "34       *** Not Classified   \n",
       "\n",
       "                                                 text  dset  \n",
       "15  other fall to lower level, unspecified an empl...  OSHA  \n",
       "16  attempted break in of wgpsn vehicle outside em...  ORGP  \n",
       "17  Employee partially fell through rooflight whil...  MANF  \n",
       "18  other fall to lower level less than 6 feet an ...  OSHA  \n",
       "19  an employee received a splinter to the hand fr...  ORGP  \n",
       "20  injury to right hand  ip was in the mess hall ...  ORGP  \n",
       "21  2 workers was confirmed as covid-19 infection....  ORGP  \n",
       "22  IP suffered tendon injury to his right shoulde...  MANF  \n",
       "23  Worker broke leg when he became partially trap...  MANF  \n",
       "24  lower back pain while carrying buckets employe...  ORGP  \n",
       "25  the sub-contractor employee was working more t...  ORGP  \n",
       "26  thrown, fell, or jumped from animal being ridd...  OSHA  \n",
       "27  the drillers struck 12-inch sewer line coming ...  ORGP  \n",
       "28  other fall to lower level 26 to 30 feet a temp...  OSHA  \n",
       "29  struck against moving part of machinery or equ...  OSHA  \n",
       "30  climbing or stepping up or down-single episode...  OSHA  \n",
       "31  ee tested positive for covid-19 ee tested posi...  ORGP  \n",
       "32  boom of awp came in contact with materials sto...  ORGP  \n",
       "33  other fall to lower level, unspecified an empl...  OSHA  \n",
       "34  employee was performing work inside unit witho...  ORGP  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df['category'] = cats\n",
    "out_df[15:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24f35742",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18e4fb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_text = 'employee was grinding with a four-inch grinder on an iron support in the compressor building when he felt discomfort to his left eye.'\n",
    "pattern = '(\\\\bemployee .* discomfort .* eye\\\\b)'\n",
    "rbfuncts.check_presence(pattern, chk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b090083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this me fault desire how you doing'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this me fault/desire how you doing\".replace('/', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7babf92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_text = 'IP suffered tendon injury to his right shoulder while moving scaffold material that had been returned from site.'\n",
    "pattern = '(\\\\bmoving.*with.*skid\\\\b)|(\\\\bwhil.*moving.*stone\\\\b)|(\\\\bdamaged.*while.*mov.*materials\\\\b)|(\\\\bwhile moving scaffold\\\\b)'\n",
    "rbfuncts.check_presence(pattern, chk_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c6c202f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(54, 60), match='moving'>\n"
     ]
    }
   ],
   "source": [
    "any_match = re.search('moving\\\\b', chk_text)\n",
    "print(any_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2c4d33f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2e80988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hjkwhkw whkw w khjwkhww</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text\n",
       "0  hjkwhkw whkw w khjwkhww"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "text_in = StringIO('hjkwhkw whkw w khjwkhww')\n",
    "tmp = pd.DataFrame(text_in, columns = ['text'])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957fdb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
